@article{Wang:2009:PGL,
	author = {Wang, Huamin and Liao, Miao and Zhang, Qing and Yang, Ruigang and Turk, Greg},
	title = {Physically guided liquid surface modeling from videos},
	year = {2009},
	issue_date = {August 2009},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {28},
	number = {3},
	issn = {0730-0301},
	url = {https://doi.org/10.1145/1531326.1531396},
	doi = {10.1145/1531326.1531396},
	abstract = {We present an image-based reconstruction framework to model real water scenes captured by stereoscopic video. In contrast to many image-based modeling techniques that rely on user interaction to obtain high-quality 3D models, we instead apply automatically calculated physically-based constraints to refine the initial model. The combination of image-based reconstruction with physically-based simulation allows us to model complex and dynamic objects such as fluid. Using a depth map sequence as initial conditions, we use a physically based approach that automatically fills in missing regions, removes outliers, and refines the geometric shape so that the final 3D model is consistent to both the input video data and the laws of physics. Physically-guided modeling also makes interpolation or extrapolation in the space-time domain possible, and even allows the fusion of depth maps that were taken at different times or viewpoints. We demonstrated the effectiveness of our framework with a number of real scenes, all captured using only a single pair of cameras.},
	journal = {ACM Trans. Graph. (SIGGRAPH)},
	month = {jul},
	articleno = {90},
	numpages = {11},
	keywords = {image-based reconstruction, physically-based fluid simulation, space-time model completion}
}

@article{Ray:2009:MST,
	author={Nicolas Ray and Bruno L\'{e}vy and Huamin Wang and Greg Turk and Bruno Vallet},
	title={Material Space Texturing},
	year={2009},
	issue_data={September 2009},
	publisher={Wiley},	
	volume={28},
	number={6},	
	url={https://doi.org/10.1111/j.1467-8659.2009.01423.x},	
	doi={10.1111/j.1467-8659.2009.01423.x},	
	abstract={Many objects have patterns that vary in appearance at different surface locations. We say that these are differences in materials, and we present a material-space approach for interactively designing such textures. At the heart of our approach is a new method to pre-calculate and use a 3D texture tile that is periodic in the spatial dimensions (s, t) and that also has a material axis along which the materials change smoothly. Given two textures and their feature masks, our algorithm produces such a tile in two steps. The first step resolves the features morphing by a level set advection approach, improved to ensure convergence. The second step performs the texture synthesis at each slice in material-space, constrained by the morphed feature masks. With such tiles, our system lets a user interactively place and edit textures on a surface, and in particular, allows the user to specify which material appears at given positions on the object. Additional operations include changing the scale and orientation of the texture. We support these operations by using a global surface parameterization that is closely related to quad re-meshing. Re-parameterization is performed on-the-fly whenever the user's constraints are modified.},	
	journal={Computer Graphics Forum},
	month={sep},
	pages={1659--1669},
	keywords={texture mapping, texture synthesis, varying texture}	
}

@inproceedings{Liao:2009:MDO,
	author={Miao Liao and Qing Zhang and Huamin Wang and Ruigang Yang and Minglun Gong},
	booktitle={2009 IEEE 12th International Conference on Computer Vision (ICCV)}, 
	title={Modeling deformable objects from a single depth camera}, 
	year={2009},
	volume={},
	number={},
	pages={167--174},
	abstract={We propose a novel approach to reconstruct complete 3D deformable models over time by a single depth camera, provided that most parts of the models are observed by the camera at least once. The core of this algorithm is based on the assumption that the deformation is continuous and predictable in a short temporal interval. While the camera can only capture part of a whole surface at any time instant, partial surfaces reconstructed from different times are assembled together to form a complete 3D surface for each time instant, even when the shape is under severe deformation. A mesh warping algorithm based on linear mesh deformation is used to align different partial surfaces. A volumetric method is then used to combine partial surfaces, fix missing holes, and smooth alignment errors. Our experiment shows that this approach is able to reconstruct visually plausible 3D surface deformation results with a single camera.},	
	keywords={deformable models,cameras,surface reconstruction,layout,assembly,shape,stereo vision,fuses,image sequences,focusing},
	doi={10.1109/ICCV.2009.5459161}
}